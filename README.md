# Acessibilidade_Parte_4_Analise_de_Sentimentos_LIBRAS

Esse projeto tem por objetivo tentar realizar a analise de sentimentos em videos de libras, utilizando os dados presentes nos demais repositórios do projeto acessibilidade.

Esse repositorio contem videos (do modelo voluntário Hugo da Hand Talk) e um caderno do google Colab para extrair a posição das mãos (através da estratégia presente em https://github.com/LucaswasTaken/Acessibilidade_Parte_3_Angulo_dedos), e analisar os sentimentos destas expressões em LIBRAS (através de uma rede similar ao apresentado em https://github.com/LucaswasTaken/Acessibilidade_Parte_1_Analise_de_Sentimentos).

![Alt Text](https://miro.medium.com/max/655/1*IUyiGzUz6h8hdnCpooKfhQ.gif)

![alt text](https://miro.medium.com/max/299/1*ZlQgzLSAiJXtNE35fckIzg.png)



Fora os videos presentes no repositório, são utilizados dados presentes na literatura, cujos datasets são elencados aqui:
https://minds.eng.ufmg.br/project/4

Como não é possível gerar as frases completas com os dados da literatura, como fazemos com o Hugo, as frases são divididas em mono, bi e trigramas  (usando combinações de palavras como apresentadas em https://github.com/LucaswasTaken/Acessibilidade_Parte_2_Combinacao_de_textos) para reproduzir elementos classificados como negativos pela rede de análise de sentimentos da lingua portuguese (apresentado em https://github.com/LucaswasTaken/Acessibilidade_Parte_1_Analise_de_Sentimentos).

O repositório ainda está em construção, e será atualizado ao longo das próximas semanas, juntamente com os código do Google Collab.

Link Google Collab: https://colab.research.google.com/drive/1Hsfo-iZAitGYD6dH4cW3L7J4nM0kBdVl?usp=sharing
